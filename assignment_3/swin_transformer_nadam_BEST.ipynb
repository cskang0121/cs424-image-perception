{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "172a2f9e",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-04-27T19:30:49.472630Z",
     "iopub.status.busy": "2023-04-27T19:30:49.472351Z",
     "iopub.status.idle": "2023-04-27T19:30:49.477331Z",
     "shell.execute_reply": "2023-04-27T19:30:49.476809Z"
    },
    "papermill": {
     "duration": 0.01611,
     "end_time": "2023-04-27T19:30:49.478694",
     "exception": false,
     "start_time": "2023-04-27T19:30:49.462584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow_hub\n",
    "# !pip install tfswin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d26b74c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T19:30:49.505605Z",
     "iopub.status.busy": "2023-04-27T19:30:49.505319Z",
     "iopub.status.idle": "2023-04-27T19:30:52.118265Z",
     "shell.execute_reply": "2023-04-27T19:30:52.117575Z"
    },
    "papermill": {
     "duration": 2.622967,
     "end_time": "2023-04-27T19:30:52.120132",
     "exception": false,
     "start_time": "2023-04-27T19:30:49.497165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-28 03:30:49.516434: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-28 03:30:50.384652: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/apps/software/cuDNN/8.1.1.33-CUDA-11.2.2/lib:/opt/apps/software/CUDA/11.2.2/nvvm/lib64:/opt/apps/software/CUDA/11.2.2/extras/CUPTI/lib64:/opt/apps/software/CUDA/11.2.2/lib:/opt/apps/software/Python/3.7.13-GCCcore-11.2.0/lib:/opt/apps/software/OpenSSL/1.1/lib:/opt/apps/software/libffi/3.4.2-GCCcore-11.2.0/lib64:/opt/apps/software/GMP/6.2.1-GCCcore-11.2.0/lib:/opt/apps/software/XZ/5.2.5-GCCcore-11.2.0/lib:/opt/apps/software/SQLite/3.36-GCCcore-11.2.0/lib:/opt/apps/software/Tcl/8.6.11-GCCcore-11.2.0/lib:/opt/apps/software/libreadline/8.1-GCCcore-11.2.0/lib:/opt/apps/software/ncurses/6.2-GCCcore-11.2.0/lib:/opt/apps/software/bzip2/1.0.8-GCCcore-11.2.0/lib:/opt/apps/software/binutils/2.37-GCCcore-11.2.0/lib:/opt/apps/software/zlib/1.2.11-GCCcore-11.2.0/lib:/opt/apps/software/GCCcore/11.2.0/lib64\n",
      "2023-04-28 03:30:50.384855: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/apps/software/cuDNN/8.1.1.33-CUDA-11.2.2/lib:/opt/apps/software/CUDA/11.2.2/nvvm/lib64:/opt/apps/software/CUDA/11.2.2/extras/CUPTI/lib64:/opt/apps/software/CUDA/11.2.2/lib:/opt/apps/software/Python/3.7.13-GCCcore-11.2.0/lib:/opt/apps/software/OpenSSL/1.1/lib:/opt/apps/software/libffi/3.4.2-GCCcore-11.2.0/lib64:/opt/apps/software/GMP/6.2.1-GCCcore-11.2.0/lib:/opt/apps/software/XZ/5.2.5-GCCcore-11.2.0/lib:/opt/apps/software/SQLite/3.36-GCCcore-11.2.0/lib:/opt/apps/software/Tcl/8.6.11-GCCcore-11.2.0/lib:/opt/apps/software/libreadline/8.1-GCCcore-11.2.0/lib:/opt/apps/software/ncurses/6.2-GCCcore-11.2.0/lib:/opt/apps/software/bzip2/1.0.8-GCCcore-11.2.0/lib:/opt/apps/software/binutils/2.37-GCCcore-11.2.0/lib:/opt/apps/software/zlib/1.2.11-GCCcore-11.2.0/lib:/opt/apps/software/GCCcore/11.2.0/lib64\n",
      "2023-04-28 03:30:50.384864: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22610 images belonging to 59 classes.\n",
      "Found 5626 images belonging to 59 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.applications import Xception\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Dense, Flatten , Input , Lambda\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "train_dir = '/common/scratch/projectgrps/CS424/assets/20230328/test_1/train_'\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    \n",
    "    rescale=1./255,\n",
    "    \n",
    "    validation_split=0.20,\n",
    "    \n",
    "    rotation_range=20,\n",
    "    \n",
    "    width_shift_range=0.2,\n",
    "    \n",
    "    height_shift_range=0.2,\n",
    "    \n",
    "    shear_range=0.2,\n",
    "    \n",
    "    zoom_range=0.2,\n",
    "    \n",
    "    horizontal_flip=True,\n",
    "    \n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "batch_size = 32 \n",
    "\n",
    "num_classes = 59\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    \n",
    "    train_dir,\n",
    "    \n",
    "    target_size=(224, 224),\n",
    "    \n",
    "    batch_size=batch_size,\n",
    "    \n",
    "    class_mode='categorical',\n",
    "    \n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    \n",
    "    train_dir,\n",
    "    \n",
    "    target_size=(224, 224),\n",
    "    \n",
    "    batch_size=batch_size,\n",
    "    \n",
    "    class_mode='categorical',\n",
    "    \n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c48441ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T19:30:52.155471Z",
     "iopub.status.busy": "2023-04-27T19:30:52.155028Z",
     "iopub.status.idle": "2023-04-27T19:31:04.584627Z",
     "shell.execute_reply": "2023-04-27T19:31:04.584015Z"
    },
    "papermill": {
     "duration": 12.458333,
     "end_time": "2023-04-27T19:31:04.586436",
     "exception": false,
     "start_time": "2023-04-27T19:30:52.128103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-28 03:30:52.444612: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-28 03:30:52.877001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22284 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:41:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /common/home/users/c/cskang.2020/jupyterlab-venv-tf/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import tensorflow.keras.regularizers as regularizers\n",
    "\n",
    "from tfswin.model import SwinTransformerBase224\n",
    "\n",
    "swin = SwinTransformerBase224(include_top=False)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Input((224, 224, 3)),\n",
    "    \n",
    "    swin,\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(512, activation='relu', kernel_regularizer=regularizers.L2(0.01)),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu', kernel_regularizer=regularizers.L2(0.01)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu', kernel_regularizer=regularizers.L2(0.01)),\n",
    "    \n",
    "    Dense(train_generator.num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c019c2c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T19:31:04.632789Z",
     "iopub.status.busy": "2023-04-27T19:31:04.632563Z",
     "iopub.status.idle": "2023-04-27T19:31:04.645070Z",
     "shell.execute_reply": "2023-04-27T19:31:04.644553Z"
    },
    "papermill": {
     "duration": 0.021234,
     "end_time": "2023-04-27T19:31:04.646313",
     "exception": false,
     "start_time": "2023-04-27T19:31:04.625079",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.4955508474576271,\n",
       " 1: 0.5463199442767588,\n",
       " 2: 0.38409010528606796,\n",
       " 3: 1.5952542372881355,\n",
       " 4: 1.6389598328302764,\n",
       " 5: 0.6856393570006314,\n",
       " 6: 1.7092009685230025,\n",
       " 7: 1.7092009685230025,\n",
       " 8: 0.5974734971116613,\n",
       " 9: 0.5513551511364524,\n",
       " 10: 1.7214973783684917,\n",
       " 11: 1.7214973783684917,\n",
       " 12: 1.7214973783684917,\n",
       " 13: 1.7214973783684917,\n",
       " 14: 1.7092009685230025,\n",
       " 15: 1.6851277154452136,\n",
       " 16: 1.2528174638388498,\n",
       " 17: 1.8841585479781129,\n",
       " 18: 1.7214973783684917,\n",
       " 19: 1.7214973783684917,\n",
       " 20: 0.6012264713397496,\n",
       " 21: 1.6733436055469955,\n",
       " 22: 0.7058647067646617,\n",
       " 23: 1.5952542372881355,\n",
       " 24: 1.7214973783684917,\n",
       " 25: 1.6970789758384421,\n",
       " 26: 1.2728092318788315,\n",
       " 27: 1.661723163841808,\n",
       " 28: 1.6733436055469955,\n",
       " 29: 0.3687028283408634,\n",
       " 30: 0.6996729110912875,\n",
       " 31: 0.7871320249776985,\n",
       " 32: 0.49748053137883647,\n",
       " 33: 1.6733436055469955,\n",
       " 34: 1.246292372881356,\n",
       " 35: 1.7092009685230025,\n",
       " 36: 0.3264503896224015,\n",
       " 37: 1.7214973783684917,\n",
       " 38: 1.7214973783684917,\n",
       " 39: 0.38719763040974164,\n",
       " 40: 1.6733436055469955,\n",
       " 41: 1.6970789758384421,\n",
       " 42: 1.7092009685230025,\n",
       " 43: 1.7214973783684917,\n",
       " 44: 1.7092009685230025,\n",
       " 45: 1.1964406779661017,\n",
       " 46: 1.5846896396902008,\n",
       " 47: 1.6970789758384421,\n",
       " 48: 1.7092009685230025,\n",
       " 49: 1.6168117269812186,\n",
       " 50: 1.1787592886365534,\n",
       " 51: 0.7121670702179177,\n",
       " 52: 1.6675131400224414,\n",
       " 53: 0.6996729110912875,\n",
       " 54: 0.4776210291281843,\n",
       " 55: 1.6851277154452136,\n",
       " 56: 1.6502630040911748,\n",
       " 57: 0.4001473839351511,\n",
       " 58: 1.6502630040911748}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples = [320,\n",
    "876,\n",
    "1246,\n",
    "300,\n",
    "292,\n",
    "698,\n",
    "280,\n",
    "280,\n",
    "801,\n",
    "868,\n",
    "278,\n",
    "278,\n",
    "278,\n",
    "278,\n",
    "280,\n",
    "284,\n",
    "382,\n",
    "254,\n",
    "278,\n",
    "278,\n",
    "796,\n",
    "286,\n",
    "678,\n",
    "300,\n",
    "278,\n",
    "282,\n",
    "376,\n",
    "288,\n",
    "286,\n",
    "1298,\n",
    "684,\n",
    "608,\n",
    "962,\n",
    "286,\n",
    "384,\n",
    "280,\n",
    "1466,\n",
    "278,\n",
    "278,\n",
    "1236,\n",
    "286,\n",
    "282,\n",
    "280,\n",
    "278,\n",
    "280,\n",
    "400,\n",
    "302,\n",
    "282,\n",
    "280,\n",
    "296,\n",
    "406,\n",
    "672,\n",
    "287,\n",
    "684,\n",
    "1002,\n",
    "284,\n",
    "290,\n",
    "1196,\n",
    "290]\n",
    "\n",
    "import numpy as np\n",
    "total_classes = len(num_samples)\n",
    "total_samples = np.sum(num_samples)\n",
    "class_weights = {}\n",
    "\n",
    "for i in range(len(num_samples)):\n",
    "    class_weights[i] = total_samples/(total_classes * num_samples[i])\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6be5f9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T19:31:04.661031Z",
     "iopub.status.busy": "2023-04-27T19:31:04.660805Z",
     "iopub.status.idle": "2023-04-28T03:24:16.797486Z",
     "shell.execute_reply": "2023-04-28T03:24:16.796833Z"
    },
    "papermill": {
     "duration": 28393.719297,
     "end_time": "2023-04-28T03:24:18.372664",
     "exception": false,
     "start_time": "2023-04-27T19:31:04.653367",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-28 03:32:02.808309: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8101\n",
      "2023-04-28 03:32:03.991725: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-04-28 03:32:04.544075: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x1e49c800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-04-28 03:32:04.544128: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-04-28 03:32:04.553020: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-04-28 03:32:04.720009: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706/706 [==============================] - ETA: 0s - loss: 7.9942 - accuracy: 0.5098\n",
      "Epoch 1: val_accuracy improved from -inf to 0.77286, saving model to swin_best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as proj_layer_call_fn, proj_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, norm_layer_call_fn, norm_layer_call_and_return_conditional_losses while saving (showing 5 of 641). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706/706 [==============================] - 861s 1s/step - loss: 7.9942 - accuracy: 0.5098 - val_loss: 5.4717 - val_accuracy: 0.7729 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 4.7203 - accuracy: 0.7776\n",
      "Epoch 2: val_accuracy improved from 0.77286 to 0.86161, saving model to swin_best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as proj_layer_call_fn, proj_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, norm_layer_call_fn, norm_layer_call_and_return_conditional_losses while saving (showing 5 of 641). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706/706 [==============================] - 739s 1s/step - loss: 4.7203 - accuracy: 0.7776 - val_loss: 3.8842 - val_accuracy: 0.8616 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 3.5449 - accuracy: 0.8270\n",
      "Epoch 3: val_accuracy improved from 0.86161 to 0.87268, saving model to swin_best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as proj_layer_call_fn, proj_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, norm_layer_call_fn, norm_layer_call_and_return_conditional_losses while saving (showing 5 of 641). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706/706 [==============================] - 736s 1s/step - loss: 3.5449 - accuracy: 0.8270 - val_loss: 3.0618 - val_accuracy: 0.8727 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 2.8096 - accuracy: 0.8478\n",
      "Epoch 4: val_accuracy improved from 0.87268 to 0.90125, saving model to swin_best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as proj_layer_call_fn, proj_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, norm_layer_call_fn, norm_layer_call_and_return_conditional_losses while saving (showing 5 of 641). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706/706 [==============================] - 737s 1s/step - loss: 2.8096 - accuracy: 0.8478 - val_loss: 2.4398 - val_accuracy: 0.9013 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 2.3134 - accuracy: 0.8649\n",
      "Epoch 5: val_accuracy did not improve from 0.90125\n",
      "706/706 [==============================] - 647s 915ms/step - loss: 2.3134 - accuracy: 0.8649 - val_loss: 2.1131 - val_accuracy: 0.8877 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 1.9480 - accuracy: 0.8744\n",
      "Epoch 6: val_accuracy improved from 0.90125 to 0.90268, saving model to swin_best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as proj_layer_call_fn, proj_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, norm_layer_call_fn, norm_layer_call_and_return_conditional_losses while saving (showing 5 of 641). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706/706 [==============================] - 750s 1s/step - loss: 1.9480 - accuracy: 0.8744 - val_loss: 1.7624 - val_accuracy: 0.9027 - lr: 1.0000e-04\n",
      "Epoch 7/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 1.6504 - accuracy: 0.8866\n",
      "Epoch 7: val_accuracy improved from 0.90268 to 0.90714, saving model to swin_best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as proj_layer_call_fn, proj_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, norm_layer_call_fn, norm_layer_call_and_return_conditional_losses while saving (showing 5 of 641). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706/706 [==============================] - 744s 1s/step - loss: 1.6504 - accuracy: 0.8866 - val_loss: 1.5368 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 8/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 1.4130 - accuracy: 0.8983\n",
      "Epoch 8: val_accuracy improved from 0.90714 to 0.91196, saving model to swin_best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as proj_layer_call_fn, proj_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, norm_layer_call_fn, norm_layer_call_and_return_conditional_losses while saving (showing 5 of 641). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706/706 [==============================] - 738s 1s/step - loss: 1.4130 - accuracy: 0.8983 - val_loss: 1.3111 - val_accuracy: 0.9120 - lr: 1.0000e-04\n",
      "Epoch 9/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 1.2500 - accuracy: 0.9003\n",
      "Epoch 9: val_accuracy improved from 0.91196 to 0.92107, saving model to swin_best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as proj_layer_call_fn, proj_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, norm_layer_call_fn, norm_layer_call_and_return_conditional_losses while saving (showing 5 of 641). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706/706 [==============================] - 736s 1s/step - loss: 1.2500 - accuracy: 0.9003 - val_loss: 1.1557 - val_accuracy: 0.9211 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 1.1061 - accuracy: 0.9070\n",
      "Epoch 10: val_accuracy did not improve from 0.92107\n",
      "706/706 [==============================] - 648s 917ms/step - loss: 1.1061 - accuracy: 0.9070 - val_loss: 1.0685 - val_accuracy: 0.9182 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 1.0007 - accuracy: 0.9086\n",
      "Epoch 11: val_accuracy improved from 0.92107 to 0.92661, saving model to swin_best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as proj_layer_call_fn, proj_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, norm_layer_call_fn, norm_layer_call_and_return_conditional_losses while saving (showing 5 of 641). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706/706 [==============================] - 771s 1s/step - loss: 1.0007 - accuracy: 0.9086 - val_loss: 0.9268 - val_accuracy: 0.9266 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 0.8899 - accuracy: 0.9148\n",
      "Epoch 12: val_accuracy improved from 0.92661 to 0.93268, saving model to swin_best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as proj_layer_call_fn, proj_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, norm_layer_call_fn, norm_layer_call_and_return_conditional_losses while saving (showing 5 of 641). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706/706 [==============================] - 738s 1s/step - loss: 0.8899 - accuracy: 0.9148 - val_loss: 0.8332 - val_accuracy: 0.9327 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 0.8122 - accuracy: 0.9193\n",
      "Epoch 13: val_accuracy did not improve from 0.93268\n",
      "706/706 [==============================] - 646s 915ms/step - loss: 0.8122 - accuracy: 0.9193 - val_loss: 0.8041 - val_accuracy: 0.9209 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 0.7509 - accuracy: 0.9185\n",
      "Epoch 14: val_accuracy improved from 0.93268 to 0.94964, saving model to swin_best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as proj_layer_call_fn, proj_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, norm_layer_call_fn, norm_layer_call_and_return_conditional_losses while saving (showing 5 of 641). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706/706 [==============================] - 738s 1s/step - loss: 0.7509 - accuracy: 0.9185 - val_loss: 0.6541 - val_accuracy: 0.9496 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 0.6672 - accuracy: 0.9274\n",
      "Epoch 15: val_accuracy did not improve from 0.94964\n",
      "706/706 [==============================] - 658s 931ms/step - loss: 0.6672 - accuracy: 0.9274 - val_loss: 0.6353 - val_accuracy: 0.9420 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 0.6177 - accuracy: 0.9270\n",
      "Epoch 16: val_accuracy did not improve from 0.94964\n",
      "706/706 [==============================] - 645s 913ms/step - loss: 0.6177 - accuracy: 0.9270 - val_loss: 0.5867 - val_accuracy: 0.9421 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 0.5552 - accuracy: 0.9378\n",
      "Epoch 17: val_accuracy improved from 0.94964 to 0.95161, saving model to swin_best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as proj_layer_call_fn, proj_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, norm_layer_call_fn, norm_layer_call_and_return_conditional_losses while saving (showing 5 of 641). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706/706 [==============================] - 736s 1s/step - loss: 0.5552 - accuracy: 0.9378 - val_loss: 0.5394 - val_accuracy: 0.9516 - lr: 1.0000e-04\n",
      "Epoch 18/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 0.5337 - accuracy: 0.9340\n",
      "Epoch 18: val_accuracy did not improve from 0.95161\n",
      "706/706 [==============================] - 645s 914ms/step - loss: 0.5337 - accuracy: 0.9340 - val_loss: 0.4937 - val_accuracy: 0.9498 - lr: 1.0000e-04\n",
      "Epoch 19/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 0.5155 - accuracy: 0.9298\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "\n",
      "Epoch 19: val_accuracy did not improve from 0.95161\n",
      "706/706 [==============================] - 696s 986ms/step - loss: 0.5155 - accuracy: 0.9298 - val_loss: 0.5160 - val_accuracy: 0.9398 - lr: 1.0000e-04\n",
      "Epoch 20/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 0.3922 - accuracy: 0.9663\n",
      "Epoch 20: val_accuracy improved from 0.95161 to 0.97429, saving model to swin_best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as proj_layer_call_fn, proj_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, norm_layer_call_fn, norm_layer_call_and_return_conditional_losses while saving (showing 5 of 641). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706/706 [==============================] - 729s 1s/step - loss: 0.3922 - accuracy: 0.9663 - val_loss: 0.3793 - val_accuracy: 0.9743 - lr: 1.0000e-05\n",
      "Epoch 21/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 0.3635 - accuracy: 0.9736\n",
      "Epoch 21: val_accuracy improved from 0.97429 to 0.97571, saving model to swin_best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as proj_layer_call_fn, proj_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, norm_layer_call_fn, norm_layer_call_and_return_conditional_losses while saving (showing 5 of 641). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706/706 [==============================] - 709s 1s/step - loss: 0.3635 - accuracy: 0.9736 - val_loss: 0.3752 - val_accuracy: 0.9757 - lr: 1.0000e-05\n",
      "Epoch 22/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 0.3442 - accuracy: 0.9787\n",
      "Epoch 22: val_accuracy improved from 0.97571 to 0.97768, saving model to swin_best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as proj_layer_call_fn, proj_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, norm_layer_call_fn, norm_layer_call_and_return_conditional_losses while saving (showing 5 of 641). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706/706 [==============================] - 709s 1s/step - loss: 0.3442 - accuracy: 0.9787 - val_loss: 0.3649 - val_accuracy: 0.9777 - lr: 1.0000e-05\n",
      "Epoch 23/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 0.3333 - accuracy: 0.9822\n",
      "Epoch 23: val_accuracy improved from 0.97768 to 0.97982, saving model to swin_best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as proj_layer_call_fn, proj_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, norm_layer_call_fn, norm_layer_call_and_return_conditional_losses while saving (showing 5 of 641). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706/706 [==============================] - 709s 1s/step - loss: 0.3333 - accuracy: 0.9822 - val_loss: 0.3491 - val_accuracy: 0.9798 - lr: 1.0000e-05\n",
      "Epoch 24/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 0.3232 - accuracy: 0.9816\n",
      "Epoch 24: val_accuracy improved from 0.97982 to 0.98054, saving model to swin_best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as proj_layer_call_fn, proj_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, norm_layer_call_fn, norm_layer_call_and_return_conditional_losses while saving (showing 5 of 641). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706/706 [==============================] - 732s 1s/step - loss: 0.3232 - accuracy: 0.9816 - val_loss: 0.3489 - val_accuracy: 0.9805 - lr: 1.0000e-05\n",
      "Epoch 25/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 0.3129 - accuracy: 0.9839\n",
      "Epoch 25: val_accuracy improved from 0.98054 to 0.98125, saving model to swin_best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as proj_layer_call_fn, proj_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, norm_layer_call_fn, norm_layer_call_and_return_conditional_losses while saving (showing 5 of 641). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706/706 [==============================] - 861s 1s/step - loss: 0.3129 - accuracy: 0.9839 - val_loss: 0.3307 - val_accuracy: 0.9812 - lr: 1.0000e-05\n",
      "Epoch 26/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 0.3008 - accuracy: 0.9865\n",
      "Epoch 26: val_accuracy improved from 0.98125 to 0.98196, saving model to swin_best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as proj_layer_call_fn, proj_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, norm_layer_call_fn, norm_layer_call_and_return_conditional_losses while saving (showing 5 of 641). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706/706 [==============================] - 708s 1s/step - loss: 0.3008 - accuracy: 0.9865 - val_loss: 0.3271 - val_accuracy: 0.9820 - lr: 1.0000e-05\n",
      "Epoch 27/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 0.2964 - accuracy: 0.9853\n",
      "Epoch 27: val_accuracy improved from 0.98196 to 0.98500, saving model to swin_best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as proj_layer_call_fn, proj_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, norm_layer_call_fn, norm_layer_call_and_return_conditional_losses while saving (showing 5 of 641). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706/706 [==============================] - 708s 1s/step - loss: 0.2964 - accuracy: 0.9853 - val_loss: 0.3120 - val_accuracy: 0.9850 - lr: 1.0000e-05\n",
      "Epoch 28/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 0.2853 - accuracy: 0.9879\n",
      "Epoch 28: val_accuracy improved from 0.98500 to 0.98518, saving model to swin_best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as proj_layer_call_fn, proj_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, norm_layer_call_fn, norm_layer_call_and_return_conditional_losses while saving (showing 5 of 641). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706/706 [==============================] - 709s 1s/step - loss: 0.2853 - accuracy: 0.9879 - val_loss: 0.3012 - val_accuracy: 0.9852 - lr: 1.0000e-05\n",
      "Epoch 29/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 0.2834 - accuracy: 0.9861\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "\n",
      "Epoch 29: val_accuracy did not improve from 0.98518\n",
      "706/706 [==============================] - 663s 939ms/step - loss: 0.2834 - accuracy: 0.9861 - val_loss: 0.3051 - val_accuracy: 0.9848 - lr: 1.0000e-05\n",
      "Epoch 30/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 0.2733 - accuracy: 0.9904\n",
      "Epoch 30: val_accuracy improved from 0.98518 to 0.98679, saving model to swin_best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as proj_layer_call_fn, proj_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, norm_layer_call_fn, norm_layer_call_and_return_conditional_losses while saving (showing 5 of 641). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706/706 [==============================] - 885s 1s/step - loss: 0.2733 - accuracy: 0.9904 - val_loss: 0.2907 - val_accuracy: 0.9868 - lr: 1.0000e-06\n",
      "Epoch 31/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 0.2716 - accuracy: 0.9899\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "\n",
      "Epoch 31: val_accuracy did not improve from 0.98679\n",
      "706/706 [==============================] - 625s 886ms/step - loss: 0.2716 - accuracy: 0.9899 - val_loss: 0.2919 - val_accuracy: 0.9862 - lr: 1.0000e-06\n",
      "Epoch 32/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 0.2707 - accuracy: 0.9899\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "\n",
      "Epoch 32: val_accuracy improved from 0.98679 to 0.98857, saving model to swin_best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as proj_layer_call_fn, proj_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, norm_layer_call_fn, norm_layer_call_and_return_conditional_losses while saving (showing 5 of 641). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706/706 [==============================] - 710s 1s/step - loss: 0.2707 - accuracy: 0.9899 - val_loss: 0.2916 - val_accuracy: 0.9886 - lr: 1.0000e-07\n",
      "Epoch 33/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 0.2707 - accuracy: 0.9907\n",
      "Epoch 33: val_accuracy did not improve from 0.98857\n",
      "706/706 [==============================] - 625s 884ms/step - loss: 0.2707 - accuracy: 0.9907 - val_loss: 0.2963 - val_accuracy: 0.9862 - lr: 1.0000e-08\n",
      "Epoch 34/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 0.2681 - accuracy: 0.9908\n",
      "Epoch 34: val_accuracy did not improve from 0.98857\n",
      "706/706 [==============================] - 624s 883ms/step - loss: 0.2681 - accuracy: 0.9908 - val_loss: 0.2942 - val_accuracy: 0.9855 - lr: 1.0000e-08\n",
      "Epoch 35/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 0.2706 - accuracy: 0.9897\n",
      "Epoch 35: val_accuracy improved from 0.98857 to 0.98911, saving model to swin_best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as proj_layer_call_fn, proj_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, norm_layer_call_fn, norm_layer_call_and_return_conditional_losses while saving (showing 5 of 641). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: swin_best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706/706 [==============================] - 870s 1s/step - loss: 0.2706 - accuracy: 0.9897 - val_loss: 0.2845 - val_accuracy: 0.9891 - lr: 1.0000e-08\n",
      "Epoch 36/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 0.2704 - accuracy: 0.9901\n",
      "Epoch 36: val_accuracy did not improve from 0.98911\n",
      "706/706 [==============================] - 710s 1s/step - loss: 0.2704 - accuracy: 0.9901 - val_loss: 0.2974 - val_accuracy: 0.9873 - lr: 1.0000e-08\n",
      "Epoch 37/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 0.2700 - accuracy: 0.9899\n",
      "Epoch 37: val_accuracy did not improve from 0.98911\n",
      "706/706 [==============================] - 623s 883ms/step - loss: 0.2700 - accuracy: 0.9899 - val_loss: 0.2879 - val_accuracy: 0.9889 - lr: 1.0000e-08\n",
      "Epoch 38/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 0.2728 - accuracy: 0.9886\n",
      "Epoch 38: val_accuracy did not improve from 0.98911\n",
      "706/706 [==============================] - 624s 883ms/step - loss: 0.2728 - accuracy: 0.9886 - val_loss: 0.2888 - val_accuracy: 0.9868 - lr: 1.0000e-08\n",
      "Epoch 39/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 0.2699 - accuracy: 0.9898\n",
      "Epoch 39: val_accuracy did not improve from 0.98911\n",
      "706/706 [==============================] - 623s 883ms/step - loss: 0.2699 - accuracy: 0.9898 - val_loss: 0.2930 - val_accuracy: 0.9871 - lr: 1.0000e-08\n",
      "Epoch 40/40\n",
      "706/706 [==============================] - ETA: 0s - loss: 0.2696 - accuracy: 0.9900\n",
      "Epoch 40: val_accuracy did not improve from 0.98911\n",
      "706/706 [==============================] - 624s 883ms/step - loss: 0.2696 - accuracy: 0.9900 - val_loss: 0.2980 - val_accuracy: 0.9866 - lr: 1.0000e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6094ec3dd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "opt = tf.keras.optimizers.experimental.Nadam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, verbose=1, mode='auto', min_lr=1e-8)\n",
    "\n",
    "checkpoint_filepath = 'swin_best'\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "                                      monitor='val_accuracy',\n",
    "                                      save_best_only=True,\n",
    "                                      mode='max',\n",
    "                                      verbose=1)\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.n // batch_size,\n",
    "    epochs=40,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.n // batch_size,\n",
    "    verbose=1,\n",
    "    callbacks=[reduce_lr, checkpoint_callback],\n",
    "    shuffle=True,\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a99c0bfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T03:24:31.435387Z",
     "iopub.status.busy": "2023-04-28T03:24:31.435115Z",
     "iopub.status.idle": "2023-04-28T03:25:01.460979Z",
     "shell.execute_reply": "2023-04-28T03:25:01.460353Z"
    },
    "papermill": {
     "duration": 31.691776,
     "end_time": "2023-04-28T03:25:01.462673",
     "exception": false,
     "start_time": "2023-04-28T03:24:29.770897",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "test_model = tf.saved_model.load('swin_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6f8ba1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T03:25:04.723893Z",
     "iopub.status.busy": "2023-04-28T03:25:04.723586Z",
     "iopub.status.idle": "2023-04-28T03:27:16.771099Z",
     "shell.execute_reply": "2023-04-28T03:27:16.770426Z"
    },
    "papermill": {
     "duration": 133.630961,
     "end_time": "2023-04-28T03:27:16.772841",
     "exception": false,
     "start_time": "2023-04-28T03:25:03.141880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "predictions = np.array([])\n",
    "\n",
    "for i in range(2950):\n",
    "    img = image.load_img('/common/scratch/projectgrps/CS424/assets/20230328/test_1/test_/' + str(i).zfill(6) + '.jpg', target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.\n",
    "    \n",
    "    probs = test_model(img_array)\n",
    "    predicted_label = np.argmax(probs)\n",
    "    predictions = np.append(predictions, predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7871a0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T03:27:19.988628Z",
     "iopub.status.busy": "2023-04-28T03:27:19.988321Z",
     "iopub.status.idle": "2023-04-28T03:27:19.992561Z",
     "shell.execute_reply": "2023-04-28T03:27:19.991926Z"
    },
    "papermill": {
     "duration": 1.56733,
     "end_time": "2023-04-28T03:27:19.993988",
     "exception": false,
     "start_time": "2023-04-28T03:27:18.426658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2950"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d2ec3ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T03:27:23.317477Z",
     "iopub.status.busy": "2023-04-28T03:27:23.317081Z",
     "iopub.status.idle": "2023-04-28T03:27:23.321424Z",
     "shell.execute_reply": "2023-04-28T03:27:23.320885Z"
    },
    "papermill": {
     "duration": 1.676057,
     "end_time": "2023-04-28T03:27:23.322915",
     "exception": false,
     "start_time": "2023-04-28T03:27:21.646858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21., 38., 21., ..., 51., 54., 29.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e111754",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T03:27:26.541601Z",
     "iopub.status.busy": "2023-04-28T03:27:26.541310Z",
     "iopub.status.idle": "2023-04-28T03:27:30.610867Z",
     "shell.execute_reply": "2023-04-28T03:27:30.610270Z"
    },
    "papermill": {
     "duration": 5.727157,
     "end_time": "2023-04-28T03:27:30.612417",
     "exception": false,
     "start_time": "2023-04-28T03:27:24.885260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_columns = ['id', 'category']\n",
    "\n",
    "result_df = pd.DataFrame(columns=data_columns)\n",
    "\n",
    "for i in range (len(predictions)):\n",
    "    new_row = {'id': str(i).zfill(6), 'category': int(predictions[i])}\n",
    "    result_df = result_df.append(new_row, ignore_index=True)\n",
    "    \n",
    "result_df.to_csv('result-swin.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69d4e916",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T03:27:33.855632Z",
     "iopub.status.busy": "2023-04-28T03:27:33.855334Z",
     "iopub.status.idle": "2023-04-28T03:27:33.897258Z",
     "shell.execute_reply": "2023-04-28T03:27:33.896715Z"
    },
    "papermill": {
     "duration": 1.615797,
     "end_time": "2023-04-28T03:27:33.898587",
     "exception": false,
     "start_time": "2023-04-28T03:27:32.282790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000001</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000002</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000003</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000004</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945</th>\n",
       "      <td>002945</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2946</th>\n",
       "      <td>002946</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2947</th>\n",
       "      <td>002947</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2948</th>\n",
       "      <td>002948</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2949</th>\n",
       "      <td>002949</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2950 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id category\n",
       "0     000000       21\n",
       "1     000001       38\n",
       "2     000002       21\n",
       "3     000003       47\n",
       "4     000004       13\n",
       "...      ...      ...\n",
       "2945  002945       51\n",
       "2946  002946       20\n",
       "2947  002947       51\n",
       "2948  002948       54\n",
       "2949  002949       29\n",
       "\n",
       "[2950 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 28610.962457,
   "end_time": "2023-04-28T03:27:39.214788",
   "environment_variables": {},
   "exception": null,
   "input_path": "/common/home/users/c/cskang.2020/assignment-3/swin-transformer.90033-Nadam.ipynb",
   "output_path": "/common/home/users/c/cskang.2020/assignment-3/swin-transformer.90033-Nadam.output.28042023033041.ipynb",
   "parameters": {},
   "start_time": "2023-04-27T19:30:48.252331",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
